{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5eaaf36",
   "metadata": {},
   "source": [
    "# 神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a19110",
   "metadata": {},
   "source": [
    "神经网络近几年飞速发展，让我们来看一看它是什么。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15fc837",
   "metadata": {},
   "source": [
    "## 什么是神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3773a5c",
   "metadata": {},
   "source": [
    "神经网络是由神经元构成的。而神经元又主要由2种计算构成：加权求和和非线性变换（又叫激活函数）。下面我们就一步一步从神经元到神经网络："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a84dae",
   "metadata": {},
   "source": [
    "### 单个神经元\n",
    "例如一个数据有3个输入$X=[x_1,x_2,x_3]^\\top$，那么神经元的数学模型就是：\n",
    "\n",
    "1. 加权求和：\n",
    "$$\n",
    "z = w_1x_1 + w_2x_2 + w_3x_3\n",
    "$$\n",
    "2. 激活函数\n",
    "$$\n",
    "a = f(z)\n",
    "$$\n",
    "其中$f(\\cdot)$是一个非线性的函数即可。常见的有ReLU, tanh, sigmoid等函数。其实，各种各样的激活函数，只要是非线性的都可以。当然这些函数的效果有好有坏。我们以sigmoid为例，那么$a=\\frac{1}{1+e^{-z}}$。\n",
    "\n",
    "那么$a$就是这个神经元的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9ae8df",
   "metadata": {},
   "source": [
    "为了增加这个模型的表现能力，往往会增加一个偏移量$b$，那么整个神经元就可以描述成：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "z &= w_{1}x_1 + w_{2}x_2 + w_{3}x_3+b\\\\\n",
    "a &= \\frac{1}{1+e^{-z}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "后面为了表述方便，我们还是把$\\frac{1}{1+e^{-z}}$写成$f(z)$的形式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7af29f",
   "metadata": {},
   "source": [
    "### 多个神经元\n",
    "上面的例子是一个神经元的例子，我们可以使用多个($I$个)神经元，那么对于第$i$个神经元，它的数学模型就是\n",
    "$$\n",
    "\\begin{aligned}\n",
    "z_i &= w_{i,1}x_1 + w_{i,2}x_2 + w_{i,3}x_3+b_i\\\\\n",
    "a_i &= f(z_i)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47236304",
   "metadata": {},
   "source": [
    "我们可以用线性代数的方法简化这个表述：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\underbrace{\\begin{bmatrix}z_1\\\\\\vdots\\\\z_I \\end{bmatrix}}_{\\boldsymbol{z}} &= \n",
    "\\begin{bmatrix}w_{1,1}x_1 + w_{1,2}x_2 + w_{1,3}x_3+b_1\\\\\\vdots \\\\w_{I,1}x_1 + w_{I,2}x_2 + w_{I,3}x_3+b_I\\end{bmatrix}\n",
    "= \n",
    "\\underbrace{\\begin{bmatrix}w_{1,1}& w_{1,2}& w_{1,3}&b_1\\\\\\vdots \\\\w_{I,1}& w_{I,2}& w_{I,3}&b_I\\end{bmatrix}}_{W}\\cdot \n",
    "\\underbrace{\\begin{bmatrix}x_1\\\\x_2\\\\x_3\\\\1\\end{bmatrix}}_{\\boldsymbol{x}}\n",
    "\\\\\n",
    "\\begin{bmatrix}a_1\\\\\\vdots\\\\a_I \\end{bmatrix} &= f\\left(\\begin{bmatrix}z_1\\\\\\vdots\\\\z_I \\end{bmatrix}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "也就是\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{z} &= W\\cdot \\boldsymbol{x}\n",
    "\\\\\n",
    "\\boldsymbol{a}  &= f\\left(\\boldsymbol{z}\\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17a392c",
   "metadata": {},
   "source": [
    "### 多个神经元+多条数据\n",
    "上面的例子中有$I$个神经元，但是只有一个数据，每个数据由3个特征组成。在实践中，数据的形式往往是$X\\in\\mathbb{R}^{E\\times M}$，其中$E$是数据的个数，$M$才是特征，也就是说\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "x_1^1 & x_2^1 & x_3^1 & 1\\\\\n",
    "\\vdots&\\vdots&\\vdots&\\vdots\\\\\n",
    "x_1^E & x_2^E & x_3^E & 1\\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "{\\boldsymbol{x}^1}^\\top\\\\\n",
    "\\vdots\\\\\n",
    "{\\boldsymbol{x}^E}^\\top\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "这里的上标$1,...,E$指的是第几个数据。因此我们需要把1.1.2的公式转置一下，得到\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Z &= X\\cdot W^\\top \\\\\n",
    "A &= f(Z)\n",
    "\\end{aligned}\n",
    "$$\n",
    "其中$X\\in\\mathbb{R}^{E\\times M}$，$W\\in\\mathbb{R}^{I\\times M}$，$Z\\in\\mathbb{R}^{E\\times I}$，$A\\in\\mathbb{R}^{E\\times I}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac3de3",
   "metadata": {},
   "source": [
    "### 多层神经元\n",
    "上面的$I$个神经元是同时接受输入数据$X$的，所以我们把它们称为一层$M$个输入$I$个输出的神经网络。然而，神经网络的丰富表达能力往往来自于深层的网络。因此，我们再增加一层网络，这个网络接收第一层网络的输出。为了方便记录，我们用大写字母的下标表示第几层，那么第一层的数学模型就是：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Z_1 &= X\\cdot W_1^\\top \\\\\n",
    "A_1 &= f(Z_1)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "第二层的原理和第一层一样，只不过它接受的信息不是$X\\in\\mathbb{R}^{E\\times M}$而是$A_1\\in\\mathbb{R}^{E\\times I_1}$，所以：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Z_2 &= A_1\\cdot W_2^\\top \\\\\n",
    "A_2 &= f(Z_2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "其中$A_1\\in\\mathbb{R}^{E\\times I_1}$，$W_2\\in\\mathbb{R}^{I_2\\times I_1}$，$Z_2\\in\\mathbb{R}^{E\\times I_2}$，$A_2\\in\\mathbb{R}^{E\\times I_2}$。\n",
    "\n",
    "借由这个原理，人们就可以不断的增加神经网络的层数。唯一需要注意的就是上一层的输出数量需要等于下一层的输入数量。第一层的输入必须等于$X$的特征数量$M$，最后一层的输出需要等于真实值$Y$的维度$N$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda5fd9e",
   "metadata": {},
   "source": [
    "## 总结\n",
    "可以看出，神经网络并没有什么神秘的地方，它只是大量神经元的堆积，而且神经元内部的计算也十分简单，也就是加权求和和一个非线性变换，仅此而已。\n",
    "\n",
    "当然，这并不意味着神经网络十分肤浅。因为在这个最基本的结构上，人们可以做大量的改进和变换。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6345a8fa",
   "metadata": {},
   "source": [
    "## 为什么神经网络变得热门"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a204479",
   "metadata": {},
   "source": [
    "可以看出，神经网络不过是一大堆简单计算的堆积，为什么神经网络很热门呢？原因有以下几点：\n",
    "\n",
    "* 智能设备的普及使得可供获取的数据急剧增加。这对于数据驱动的算法来说至关重要。\n",
    "* 硬件计算能力的提升\n",
    "* 简单的计算结构（加权求和+非线性变换）。这不仅使得入门简单，更极大的简化了优化过程。\n",
    "* 强大的表现能力：尽管计算简单，但是利用多层神经网络，依然能表达出丰富的信息[1]\n",
    "\n",
    "[1] Hornik, Kurt, Maxwell Stinchcombe, and Halbert White. \"Multilayer feedforward networks are universal approximators.\" Neural networks 2.5 (1989): 359-366."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aab0c9",
   "metadata": {},
   "source": [
    "**以后面我们会讲到神经网络中的反向传播，这就是神经网络热门的核心原因之一。**\n",
    "\n",
    "**下面我们将简单介绍一下数据集，然后用自己的代码（不用PyTorch）搭建一个最基本的神经网络。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73816ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
