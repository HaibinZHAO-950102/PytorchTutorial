{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3c8bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a034c8d",
   "metadata": {},
   "source": [
    "# 尽量不要自己给自己赋值\n",
    "## 错误例子：自己给自己赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86946be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.9978, 0.0706, 0.6378, 0.3654, 0.2720, 0.1149, 0.0122, 0.7917, 0.9183,\n",
       "        0.0512], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta1 = torch.nn.Parameter(torch.rand(10), requires_grad=True)\n",
    "eta1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed23673e",
   "metadata": {},
   "source": [
    "这里本来想让eta乘以2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82ea4780",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta1 = eta1 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67657095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9955, 0.1412, 1.2757, 0.7307, 0.5439, 0.2298, 0.0243, 1.5833, 1.8366,\n",
       "        0.1025], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b28e6057",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta1.sum().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ee839",
   "metadata": {},
   "source": [
    "结果可以看出没有梯度了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a9bfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haibinzhao/miniconda3/envs/ML/lib/python3.8/site-packages/torch/_tensor.py:1104: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1646755922314/work/build/aten/src/ATen/core/TensorBody.h:475.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "eta1.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a1a12",
   "metadata": {},
   "source": [
    "## 正确例子：赋值给其他变量名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d74691f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.2090, 0.4850, 0.3451, 0.9455, 0.2797, 0.2960, 0.1259, 0.3914, 0.3573,\n",
       "        0.1584], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta2 = torch.nn.Parameter(torch.rand(10), requires_grad=True)\n",
    "eta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb5a96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_temp = eta2 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66db1861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4179, 0.9700, 0.6903, 1.8910, 0.5594, 0.5921, 0.2518, 0.7829, 0.7146,\n",
       "        0.3169], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b658656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_temp.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "821be213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta2.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da59f5",
   "metadata": {},
   "source": [
    "# 小心直接赋值其他变量\n",
    "## 错误例子：直接赋值给别的变量后，内存里还是同一个变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e820e6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.7064, 0.7076, 0.1082, 0.1147, 0.1358, 0.9714, 0.9704, 0.2618, 0.8911,\n",
       "        0.3691], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = torch.nn.Parameter(torch.rand(10), requires_grad=True)\n",
    "v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921ad80",
   "metadata": {},
   "source": [
    "把`v1`赋值给`a`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49506fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = v1[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0389e619",
   "metadata": {},
   "source": [
    "修改`a`的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9e84a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7943, 0.3477, 0.8388, 0.9612], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data.copy_(torch.rand(4))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb488f2",
   "metadata": {},
   "source": [
    "发现`v1`的值也被改了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d73cdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.7943, 0.3477, 0.8388, 0.9612, 0.1358, 0.9714, 0.9704, 0.2618, 0.8911,\n",
       "        0.3691], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d97ff55",
   "metadata": {},
   "source": [
    "## 正确例子：用克隆的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "763f1b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.9978, 0.7118, 0.1021, 0.7963, 0.8129, 0.4852, 0.9747, 0.3141, 0.0183,\n",
       "        0.8853], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2 = torch.nn.Parameter(torch.rand(10), requires_grad=True)\n",
    "v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc257b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = v2[:4].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cfc3cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2075, 0.9243, 0.8223, 0.9775], grad_fn=<CloneBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.data.copy_(torch.rand(4))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eee5631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.9978, 0.7118, 0.1021, 0.7963, 0.8129, 0.4852, 0.9747, 0.3141, 0.0183,\n",
       "        0.8853], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb79c321",
   "metadata": {},
   "source": [
    "# 生成可学习参数时先生成，最后再包装\n",
    "## 错误例子：先生成Parameter，再变形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "185f638f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.2056],\n",
       "        [ 0.4865],\n",
       "        [-0.0678],\n",
       "        [ 0.6065],\n",
       "        [-0.6478],\n",
       "        [ 1.5539],\n",
       "        [ 2.1328],\n",
       "        [-1.8299],\n",
       "        [-0.1069],\n",
       "        [-0.2585],\n",
       "        [ 0.6403],\n",
       "        [-0.3970]], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.nn.Parameter(torch.randn(12,1), requires_grad=True)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9672158c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2056,  0.4865, -0.0678,  0.6065],\n",
       "        [-0.6478,  1.5539,  2.1328, -1.8299],\n",
       "        [-0.1069, -0.2585,  0.6403, -0.3970]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.view(3,4)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9c9cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18a27b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11de9377",
   "metadata": {},
   "source": [
    "## 正确例子：先全部初始化完成，再包装成Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c23a63e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4591],\n",
       "        [ 1.1992],\n",
       "        [-1.8990],\n",
       "        [ 1.6807],\n",
       "        [-1.4025],\n",
       "        [-1.0175],\n",
       "        [-0.7314],\n",
       "        [ 0.5964],\n",
       "        [ 0.8397],\n",
       "        [ 0.4601],\n",
       "        [ 0.5969],\n",
       "        [-1.1249]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = torch.randn(12,1)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31fcac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = k.view(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8f9cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kp = torch.nn.Parameter(k, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4509f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kp.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db7cdd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056bb60e",
   "metadata": {},
   "source": [
    "# 警惕组装变量时的错误\n",
    "## 错误例子：把变量直接拼起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fdd1bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.nn.Parameter(torch.randn(5), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95e3dfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.7823, grad_fn=<MulBackward0>),\n",
       " tensor(nan, grad_fn=<LogBackward0>),\n",
       " tensor(0.0822, grad_fn=<PowBackward0>),\n",
       " tensor(0.9989, grad_fn=<SoftplusBackward0>),\n",
       " tensor(1.0601, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a0 = a[0] * 2\n",
    "a1 = torch.log(a[1]+1)\n",
    "a2 = a[2] ** 2\n",
    "a3 = torch.nn.functional.softplus(a[3] * 2)\n",
    "a4 = a[4]\n",
    "a0, a1, a2, a3, a4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b0d655",
   "metadata": {},
   "source": [
    "组合成一个新变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e8e1a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7823,    nan, 0.0822, 0.9989, 1.0601])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1 = torch.tensor([a0, a1, a2, a3, a4])\n",
    "A1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2e5ced",
   "metadata": {},
   "source": [
    "由于重新用`tensor`包装了变量，切断了反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58f4faf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mA1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "A1.sum().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fea05e5",
   "metadata": {},
   "source": [
    "## 正确例子：建立一个变量，然后把值填进去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fa4f144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 1.3911, -1.0731,  0.2867,  0.2698,  1.0601], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fdb7b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = torch.zeros([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "818b4ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7823,    nan, 0.0822, 0.9989, 1.0601], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2[0] = a[0] * 2\n",
    "A2[1] = torch.log(a[1]+1)\n",
    "A2[2] = a[2] ** 2\n",
    "A2[3] = torch.nn.functional.softplus(a[3] * 2)\n",
    "A2[4] = a[4]\n",
    "A2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af41fa5",
   "metadata": {},
   "source": [
    "就可以使用了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9171f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "A2.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9c826d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2.0000, -13.6835,   0.5734,   1.2634,   1.0000])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3f59c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
